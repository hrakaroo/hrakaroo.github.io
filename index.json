[{"authors":["admin"],"categories":null,"content":"Joshua Gerth is a software professional with over twenty years experience in system design and software development. He is an active public speaker and has won several awards for humorous speaking.\n","date":1569888000,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1569888000,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"Joshua Gerth is a software professional with over twenty years experience in system design and software development. He is an active public speaker and has won several awards for humorous speaking.","tags":null,"title":"Joshua Gerth","type":"authors"},{"authors":null,"categories":null,"content":"","date":1577318400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577318400,"objectID":"205809978e4f76dbca8782c4b4078d43","permalink":"/project/glob-library-java/","publishdate":"2019-12-26T00:00:00Z","relpermalink":"/project/glob-library-java/","section":"project","summary":"Fast lightweight glob library for Java","tags":["Java"],"title":"Glob Library for Java","type":"project"},{"authors":null,"categories":null,"content":"","date":1574294400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1574294400,"objectID":"a6f33e008b6ed177f57f831de4c78002","permalink":"/project/ray-the-tracer/","publishdate":"2019-11-21T00:00:00Z","relpermalink":"/project/ray-the-tracer/","section":"project","summary":"Ray Tracer written in Go","tags":["Go","RayTracer"],"title":"Ray the Tracer","type":"project"},{"authors":["Joshua Gerth"],"categories":["Software Development"],"content":"This is my second post on things I'm finding interesting about the Go language. For additional background you might want to read Part 1.\nDependency Management This time I'm going to focus on dependency management and how go approaches the diamond dependency issue.\nFirst of all, Go does not support pre-compiled libraries the way Java does. (Personally, I think compiled Jar files are from a by-gone time and these days cause more harm than good, but that's not why Go doesn't have them.) Go doesn't have them because Go code compiles down into native assembly so it would be impossible to distribute anything precompiled by Go and expect it to work on more than one platform.\nSo instead, Go publishes libraries as source code with Git tags and avoids artifactory all together. When you want to use a library you create a dependency on a git repo with a specific tag version.\nThis doesn't exactly remove the diamond dependency issue as it is entirely possible to have a transitive dependency on two different versions of a library. In this case, as with Java, you still have to select the version you want to use. However, there are two substantial changes.\nCan't ignore the problem First, you don't have the option of ignoring the issue. This means that if your service builds in Go, you can be confident your code does not contain any \u0026ldquo;hidden\u0026rdquo; mismatch errors. This effectively removes an entire class of errors that you have with Java. (TBH, these don't pop up too often, but the more common a library is the greater the chance for this to happen. I've seen it with Guava libraries.) However, being able to completely remove them as a class of problems would be nice.\nConflicts identified at the source code level Second, conflicts are identified at the source code level and not at the version level. This means that PATCH version mismatches won't break your build so long as they don't change function signature (and PATCHES really shouldn't).\nI'm not saying that the way Go deals with this is perfect but it does move the problem into a first class issue and forcing a resolution. Java could take this same approach if you copied all of your dependencies into your code base as source code. But I did find it as an interesting consequence on how Go works vs Java.\n","date":1569888000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1569888000,"objectID":"0c4d4b09f635dc5d5e6c115df51b76b6","permalink":"/post/go-for-java-part2/","publishdate":"2019-10-01T00:00:00Z","relpermalink":"/post/go-for-java-part2/","section":"post","summary":"Go's approach to the diamond dependency problem.","tags":null,"title":"Go for Java Developers - Part 2","type":"post"},{"authors":["Joshua Gerth"],"categories":["Software Development"],"content":"For the last 20+ years I've been mostly focused on Java development. But recently I had an opportunity to join a team which was focused on Go and having spent the early part of my career writing C++ I was intrigued by some of the decisions Go made. So this is the first (of possibly several) posts on things I found interesting about the language and since my I have been doing mostly Java development I'm going to be comparing and contrasting from that perspective.\nGo interfaces For this first post I'm going to discuss one specific implication of how Go handles interfaces.\nIf you are unfamiliar with Go, it uses structural typing for interfaces (which is more generally called \u0026ldquo;duck typing\u0026rdquo; meaning \u0026ldquo;if it walks like a duck and talks like a duck … it's a duck.\u0026quot;) This means that if a struct in Go has functions on it which match the methods of an interface, instances of that struct are types of that interface. This sounds more complicated than it actually is so lets look at a quick example:\nSuppose you wanted to create a Person class and a Named interface in Java, that might look like:\ninterface Named { String getName(); } class Person implements Named { String name; String getName() { return name; } }  Pretty straight forward. Now, if we wanted to do a similar thing in Go it would probably look something like:\ntype Named interface { getName() string } type Person struct { name string } func (p Person) getName() string { return p.name }  Ignoring the syntax differences, what is interesting is that in Go we don't declare Person as implementing Named. This is implied by the function on Person matching the method in the Named interface. The compiler figures this out for us and instances of a Person are automatically of type Named.\nSo while this isn't necessarily a new thing (Python mostly lets you do the same thing), this was something new for a statically typed language.\nWhen I first saw this I thought \u0026ldquo;meh, so you can leave off the \u0026lsquo;implements\u0026rsquo; keyword, whatever.\u0026rdquo; But I think this feature has a really interesting implication.\nThe setup Back in Java land, let's suppose you have a function that takes an SQL PreparedStatement as one of its arguments. Something like:\nclass Db { void setValue(PreparedStatement stmt, String value) { stmt.setString(1, value); } }  You might use this like:\nPreparedStatement stmt = conn.prepareStatement(\u0026quot;SELECT …\u0026quot;); Db db = new Db(); db.setValue(stmt, \u0026quot;someValue\u0026quot;);  Writing a unit test for this would probably look something like:\nclass DbTest { @Test public void setValueTest() { Db db = new Db(); PreparedStatement stmt = ?? db.setValue(stmt, \u0026quot;dog\u0026quot;); // todo - verify the statement received the value of \u0026quot;dog\u0026quot; } }  The challenge is creating the test PreparedStatement. You could use one of the mocking frameworks in Java (Mockito, PowerMock, …) to mock the PreparedStatement and test that setValue is called with the value \u0026ldquo;dog\u0026rdquo;. While this does work, most/all of the mocking frameworks are basically a nice user interface over a rats nest of reflection calls. (Used incorrectly reflection is a tool to move compile time errors back to the runtime.) However, it is also possible to test this without using a mocking framework by building our own class which implements PreparedStatement:\nclass TestPreparedStatement implements PreparedStatement { String value; void setString(int parameterIndex, String x) { this.value = x; } ... }  An instance of our TestPreparedStatement can now be passed into our setValue method and we can later verify that the internal \u0026lsquo;value\u0026rsquo; is set to \u0026ldquo;dog\u0026rdquo;.\nAhhh … but there is a devil hidden in these details. PreparedStatement is a massive interface with well over 50 methods. In order to stub out the one method you want (setString) you are going to need to also stub out all of the other ones as well. We don't ever use them so they can all throw a RuntimeException (and thankfully most modern IDEs can automatically generate this code for you) … but you are still dealing with a lot of boilerplate code.\nThe switch Now let's take a look at this same problem in Go land. (For the sake of argument let's assume that PreparedStatement both exists in Go and works much in the same way as its Java counterpart).\ntype Db struct { } func (db Db) setValue(stmt PreparedStatement, value string) { stmt.setString(1, value) }  And again it is used like:\nstmt := conn.prepareStatement(\u0026quot;SELECT …\u0026quot;) db := Db{} db.setValue(stmt, \u0026quot;someValue\u0026quot;)  Now let's write the unit test:\nfunc SetValueTest(t* testing.T) { db := Db{} stmt := ?? db.setValue(stmt, \u0026quot;dog\u0026quot;) // todo - verify the statement received the value of 'dog }  We've once again hit the same issue. As with Java, we can use the Go's mock framework (which also uses reflection) or, as before, we can try to roll our own.\nApproaching it directly we could build out a TestPreparedStatement as:\ntype TestPreparedStatement struct { value string } func (tps TestPreparedStatement) setString(parameterIndex int, x string) { tps.value = x }  But then we are going to have the same issue as we had with Java where we also need to stub out all of the other 50+ methods in the PreparedStatement interface which is just as wasteful as it was in Java. But we do have one other option.\nDuck Typing What if we didn't stub out all of the other methods and instead created a new interface which only contained the one method we are using? So something like:\ntype StringSetter interface { setString(parameterIndex int, x string) }  Now, since our TestPreparedStatement implements this one method it is automatically a type of StringSetter. But guess what, the object returned by conn.prepareStatement is also now a type of StringSetter since it too implements setString (by virtue of it being a PreparedStatement which also requires the same method.)\nNow, we only need to change the signature of our setValue method to:\nfunc (db Db) setValue(stmt StringSetter, value string) { stmt.setString(1, value) }  This is where the power of the duck typing comes into play as doing this in Java would require modifying the definition of PreparedStatement so it explicitly extend StringSetter, which is virtually impossible. Yet in Go this is trivial as we can assign interfaces to objects by simply copying over the methods we want into the interface.\nI found this to be a surprising feature about Go and is not something I had considered before. It feels really powerful and, to be honest, I'm not yet sure if this is a good feature about the language or not, but it is an interesting one.\n","date":1564617600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1564617600,"objectID":"38c67d5b1ec54e2fc1dffc982f0a535d","permalink":"/post/go-for-java-part1/","publishdate":"2019-08-01T00:00:00Z","relpermalink":"/post/go-for-java-part1/","section":"post","summary":"Cool tricks with Go interfaces","tags":null,"title":"Go for Java Developers - Part 1","type":"post"},{"authors":["Joshua Gerth"],"categories":["Software Development","API"],"content":"The following is blog post that was written from a speech I presented about questions to consider when writing an API.\n Writing a functional API is relatively easy, but writing a good one that’s functional and empowers your users takes planning and patience. Designing a good API is about creating a sense of clarity and simplicity—it’s the bridge between your intention and your users.\nLike most software development, building an API is a creative process; it’s impossible to completely define a hard-and-fast set of rules that will work in all cases. Nevertheless, three key questions—derived from what I consider the key characteristics of a good API—can serve you well as functional guideposts as you design and write your API:\n Is your API’s usage discoverable? Is your API composable? Is your API safe to use?  Let’s take a closer look at each question.\nIs your API’s usage discoverable? In his famous book, The Design of Everyday Things, Don Norman coined the term discoverability. \u0026ldquo;When we interact with a product,\u0026rdquo; Norman wrote, \u0026ldquo;we need to figure out how to work it. This means discovering what it does, how it works, and what operations are possible.\u0026rdquo;\nTake doors, for example: We interact with these standard physical objects every day. Often, based on the presence of affordances like knobs, handles, and push bars, it’s pretty clear how to open or close a door. But on occasion, a door’s design will suggest the opposite of how it actually works, and, as a result, we require instructions before we can properly use it. Just think of how many times you pulled a handle that actually needed to be pushed.\nWhen we use a door the wrong way, we feel silly and stupid, but it’s not our fault. Actually it’s the design that’s bad.\nSomething similar can happen with a poorly designed API.\nConsider the last API you used. How did you learn to use it? Did you read all the documentation first, or did you just jump right in? Maybe you weren’t sure about all of the parameters, so you sent in null for a few values and guessed at others. Did the API throw an error message when you did something wrong, or did it fail silently without any feedback? Did the error message clearly define which parameters were optional and which were not? Did you just keep plugging away until you got it right?\nThis is how most users will learn your API.\nYour users are going to learn just enough to bootstrap themselves, and then they’ll figure the rest out as they go. With this fact in mind, you can help them along the away by increasing your API’s discoverability. You can do this through documentation; adhering to conceptual models; and using concise, symmetrical language.\nAssume your users won’t read the documentation—until they need to Just because your users won’t read your documentation doesn’t mean that you don’t need to provide it. You definitely do. But don’t design your API with the assumption that everyone will read the docs before they use it.\nSome users would rather experiment than look up an answer in the docs. Every time I use Java’s substring() method, for example, I can never remember if the second value is an offset or a length, so I just write a little program to try it out both ways. This is usually quicker for me, and more fun, than looking up the answer.\nIn many cases, users who’ve learned to distrust documentation won’t read the docs anyway, at least not until they get desperate. Documentation is notorious for being out of date or just wrong. Now, this obviously isn’t true of all documentation, but think of how many times you’ve consulted documentation—or a help system or knowledge base—and found that either it provided answers that were totally useless, or it didn’t provide any related answers at all. Plenty of documentation does a poor job of anticipating the questions users might ask or how they might ask them. Additionally, even if users have a sense of what task they want to achieve, they may lack the exact vocabulary or use different terms for that task than the docs, which can make searching difficult.\nYou should also provide plenty of examples in your documentation—because users want them. Typically, examples are the first things users look for when learning a new API. Only after they gain a little context will they go look at the rest of the documentation. Examples are how users come to understand your API as a whole.\nCreate a conceptual model of how your API works Don Norman explains that a conceptual model is \u0026ldquo;an explanation, usually highly simplified, of how something works.\u0026rdquo; Conceptual models are not schematics, and they should relate to other known conceptual models.\nA good example of a conceptual model is the file system structure used on personal computers. File systems, like those on Mac and Windows operating systems, were intentionally based on the concept of files and folders that we were already familiar with in the physical world. This made it easy for non-technical users to understand and discover how to copy, store, and retrieve files on their PCs.\nEven today, Unix uses this conceptual model of files and folders anytime a user attaches a device (e.g. a phone or external hard drive) to an operating system, which has completely eliminated the need for users to \u0026ldquo;discover\u0026rdquo; a new API every time they attach a device.\n\u0026ldquo;Objects\u0026rdquo; in object-oriented programming are another example of a conceptual model. They’re specifically called objects so that we think of them as self-defining entities. Just as a ball object on the computer might support a bounce method, as well as other methods like throw, a ball in real life, through its design, also supports bounce and throw operations. In data-oriented programming, however, you don’t get this conceptual model, so you’re more likely to have a bounce function that will throw an error if you send it anything other than a ball.\nAnother example of working within conceptual models is the use of \u0026ldquo;object\u0026rdquo; in object-oriented programming. In this programming model, objects represent physical objects from the real world, such as servers, databases, and load balancers, and developers create relationships between those objects via APIs.\nUse clear, consistent, and symmetrical language In addition to documenting your API, you should also develop and publish a terminology dictionary for your API—and then use it consistently. For example, I commonly see APIs use terms like host and hostName, and account and accountId, almost interchangeably. Forcing your users to guess what the right call might be, or constantly changing the language, does not promote discoverability.\nLike conceptual models, symmetrical language helps users work with your API with certain expectations in place. If your language is symmetrical, an open operation will be balanced with a close, and an add operation will be balanced with a delete.\nIn Python, for example, you use pop to remove an element, so the expectation would be that you’d use push to add an element, as that’s how it works in most other languages. Instead, Python uses append… and there’s plenty of Google search results from people confused by this poor discoverability.\nIs your API composable? When you build a composable API, you are letting your users select components of the API and use them in whatever pattern they want.\nSmall and composable methods are easier to describe and document than larger methods that contain a long chain of steps and caveats. They’re also easier to run regression and end-to-end tests against.\nMost importantly, though, employing composable components gives your users the tools they need to build their own workflows with your API. You can’t predict all your users’ needs, so don’t force them into one execution pattern. Instead, create composable components and then use your examples to show how to combine them into larger execution patterns.\nFor example, consider the following methods:\nsetName(firstName, lastName)  vs.\nsetFirstName(firstName) setLastName(lastName)  The second option is more composable than the first, as the second method allows you to easily update the value for lastName. With the first method you would first have to fetch the value of firstName so you could send it back in with the new value for lastName.\nThe second option is also more extensible, as you can easily add a method to set the middle name:\nsetMiddleName(middleName)  Finally, the second option is also 100% backwards compatible with existing code. If you were to update the first method to\nsetName(firstName, middleName, lastName)  you’d break the existing code.\nBoth you and your users will undoubtedly enjoy the free backwards compatibility, as building from smaller, composable components makes it much easier to extend your API as it grows; and to continue supporting support old operations alongside new ones.\nIs your API safe to use? Ensuring that your API is safe to use—that it won’t behave differently than users expect or break their workflows— is related to the discoverability of an API. But safety is so important that I want to call out the topic separately. When you publish your API, you create a relationship with your users that should be based on trust and transparency. Here’s how to make that happen:\nPractice the principle of least astonishment The principle of least astonishment tells us that a component of a system should behave in a way that most users will expect it to behave. The behavior should not astonish or surprise users.\nThe setDate method in GNU’s Coreutils, for example, surprises me every time I use it because I expect a set method to set a value and not alter it. If you set the year to any value less than 68, it automatically adds 2000 to the value; and if you set any value between 68 and 100, it automatically adds 1900. Every time I use this method, I’m astonished and have to re-read the documentation to make sure I’m using it correctly.\nFollow the contract Don’t try to interpret what you think your user is trying to do. For example, if your API expects a number, and the user provides a string, don’t try to parse a number out of the string. You aren’t doing anyone any favors: What happens when users enter an empty string: Is that 0 or null?\nDesign your API so that it’s deterministic and strict.\nTrust nothing and fail fast Similarly, your API should verify everything that users send, and immediately fail on errors. More specifically, garbage-in should not equal garbage-out. Garbage-in should fail. If your users are calling your methods with incorrect values, they may be in discovery mode, intentionally testing the boundaries and trying to figure out what is possible.\nHelp them understand what’s possible and what isn’t.\nPlan to version from the start and aggressively deprecate old versions If you change the signature or external behavior of your API, version it.\nAnd when you do roll an API’s version forward, dedicate time and resources to aggressively migrate users. If that’s not possible, try to rewrite older versions so they proxy to the new implementation. These steps will help avoid creating technical debt—which, like financial debt, definitely accrues interest over time. The longer an outdated version of your API sits around, the more ingrained it becomes in your user base, and the harder it will be to move users off of it. Set a migration date, and make it happen.\nIf you release a version that is likely to change quickly, make that fact explicit by tagging it as \u0026ldquo;incubating,\u0026rdquo; \u0026ldquo;unstable,\u0026rdquo; or \u0026ldquo;beta.\u0026rdquo; This helps provide breathing room if you need to turn off old versions of your API as you release new ones.\nSeparate your API from your implementation Finally, publish your API version separately from its implementation. The implementation is likely to change faster than the API, so don’t tie the two together.\nWhen versioning a library, for example, the API and its implementation are in the same package, so you can’t help but release them at the same time. But you can at least use semantic versioning to make it clear which parts are backwards compatible.\nFor a service, though, you can publish an API separately from its implementation. In fact, there are plenty of tools, including Apache Thrift, FlatBuffers, and Swagger, that allow you to write your API separately. With these tools, you write your spec and then build your implementation so that it implements the spec.\nNail that first impression Your API is often a user’s first impression of your system. Spend time on discoverability, composability, and safety to make sure that first impression is a good one. Proper planning and design is critical to the effectiveness and success of your API. Taking the time to think things through will help to make your API a first-class feature—not a mere afterthought or means to an end.\n","date":1559779200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1559779200,"objectID":"53f7774c155e4ba6eaf527864d19f25e","permalink":"/post/three-questions/","publishdate":"2019-06-06T00:00:00Z","relpermalink":"/post/three-questions/","section":"post","summary":"The following is blog post that was written from a speech I presented about questions to consider when writing an API.\n Writing a functional API is relatively easy, but writing a good one that’s functional and empowers your users takes planning and patience. Designing a good API is about creating a sense of clarity and simplicity—it’s the bridge between your intention and your users.\nLike most software development, building an API is a creative process; it’s impossible to completely define a hard-and-fast set of rules that will work in all cases.","tags":null,"title":"Three Questions to Ask When Writing a New API","type":"post"},{"authors":["Joshua Gerth"],"categories":["Software Development","API"],"content":"A long time ago\u0026hellip; In 1974 the first relational database was created and along with it a new user interface language was developed to make it easy to query the data. This language (or rather sub-language) was called Structured English Query Language or SEQUEL. SEQUEL would later evolved into SQL and become the preeminent language for querying relational databases. In the 45+ years since it's introduction SQL has evolved slightly but it is still largely similar to the version introduced in the 70s. What has changed during that time is how we interact with the database. Today, SQL is used significantly more by applications querying the database than by end users. This usage pattern has created its own ecosystem of utilities and libraries which help applications build SQL queries. One of the more popular libraries for building SQL queries in Java is Hibernate's Criteria Builder which uses an annotation pre-processor and a builder pattern to facilitate building SQL queries. (Java's Persistence API was based heavily on Hibernate's Criteria Builder). But, at the end of the day the builder still generates a basic SQL string which is sent to the target database, parsed and then executed. Hibernate is just one example, but there are hundreds of other libraries that exist across various languages which all seek to provide the same basic functionality. To provide an API which abstracts away the actual building of an SQL query.\nSo why do these all tools exist? Is an SQL query so complicated to construct that we need libraries and utilities to help us? In general, no, most SQL queries are relatively straightforward to construct. The problem is that SQL was designed for humans and not computers. The inclusion of the word \u0026lsquo;English\u0026rsquo; in the original name was not by chance, SQL was intended to be similar enough to English that it would be self descriptive and would only require minimal transformation from the spoken question to the actual query. SQL was not written to make querying easy from other applications. In order to query a database from an application, the application needs to build the SQL query programmatically at run time, which means that all errors in the SQL query string are also going to be discovered at run time.\nAn Impedance Mismatch Compiled languages offer an enormous advantage over interpreted languages in that you can be confident that, if the application compiles, then it does not contain any syntax errors. This assurance removes an entire class of errors that exist in pure scripting languages. Yet, by having an application generate SQL you are re-introducing the possibility of a run time syntax error. Furthermore, the errors which do get introduced are almost always related to the construction of the SQL query rather than actual column names or keywords in the query. Meaning the column names and keywords are not as likely to be the source of syntax errors as they don't normally change based on the user request. For example, an application which allows the searching of available flights is less likely to return different a type of data depending on the destination city. You may get back more or less result, but it will usually be the same basic set of information. Syntax errors around the column names and keywords are often found through basic testing and fixed.\nThe more common (and harder to find) syntax errors are introduced in the construction of the query itself.\n Did you remember a space after the \u0026lsquo;SELECT\u0026rsquo; and \u0026lsquo;FROM\u0026rsquo; keywords? Did you join your select fields with a comma, but remember to not include a comma after the last one? If this is the first filter then we need to add the \u0026lsquo;WHERE\u0026rsquo; keyword, but if this is the second one we need to add the \u0026lsquo;AND\u0026rsquo; keyword, and don't forget about the parentheses.  These types of syntax errors are often introduced based on the users search criteria and can be significantly more difficult to find with basic testing due to the sheer number of permutations. This is the real advantage of using a helper library like Hibernate Criteria Builder. They provide an assurance that if you use their libraries, the generated SQL will be free of construction syntax errors. This assurance is most often achieved through massive test coverage and a responsive development team which quickly patches any errors that are found. It would be safe to say that in the 45+ years since the introduction of SQL, millions of lines of code have been written in various languages, all attempting to work around this same basic problem. It's a huge waste of intellectual effort for what is essentially a self inflicted problem.\nWhere to go from here SQL and similar English based DSLs (domain specific languages) are immensely powerful for building complex queries quickly. As an end user, nothing is more frustrating than trying to build a complex search criteria through a form based UI. First enter the subject, then select the predicate, then enter the object, then click the plus sign to add another filter, rinse and repeat. This becomes incredibly tedious very quickly and makes building complex groupings all but impossible.\nThis is where an English based DSL really shines. It allows a seasoned user to rapidly create complex queries as they are doing it interactively and have to do minimum mapping from what they are trying to search for to the actual query they are running (just as SQL was initially designed for). But that is where the DSL should remain, as a tool for the end user. Do not just create an API which takes the DSL directly as, at best, you will be recreating the same impedance mismatch and likely forcing your users to create the same set of \u0026ldquo;builder\u0026rdquo; libraries.\nInstead, define a flexible structure which can be used to describe a query. JSON, XML or even one of the compressed protocols like Thrift or Flatbuffers could work. Users can then create their query programmatically and completely remove the risk of introducing a construction based error because they forgot a space or included a comma at the wrong location. Your API can either accept this structure directly for querying, or you can split it up and have different endpoints accept different categories of queries based on the structure of the return type. Either way, creating a well defined structure programmatically is straight forward and can easily be supported from a multitude of languages.\nAs for your UI, you are going to have to create a parser for your DSL anyhow which is going to build an intermediary representation of your query. If you merge your intermediary representation with your defined query structure it should be trivial to show the user what they would need to send to the API in order to reproduce their query in the API.\nIn this scenario your query language can continue to evolve separate from your query structure. You can even support other English based DSLs as long as they can all generate the same query structure. But what ever you do, keep the two domains separate. SQL is a terrible API.\n","date":1541030400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1541030400,"objectID":"8b858f9d008b5104e96396c1ce8df0c3","permalink":"/post/sql-terrible-api/","publishdate":"2018-11-01T00:00:00Z","relpermalink":"/post/sql-terrible-api/","section":"post","summary":"SQL was designed for humans, not computers","tags":null,"title":"SQL is a terrible API","type":"post"},{"authors":["Joshua Gerth"],"categories":["Development Process","Teams"],"content":"The following is a blog post that was written from a speech I gave about how to set the ground rules for code reviews.\n Following New Relic’s Project Upscale—an innovative reorganization intended to make our development teams more autonomous—the engineering organization formed several new teams, one of which was the New Relic Database (NRDB) team. As the name implies, the NRDB team is responsible for the development of our events database, which powers the New Relic Insights tool as well as several other products.\nWhen we formed the NRDB team, it included several senior-level software engineers. This was a highly skilled and very passionate group of developers reviewing one another’s pull requests.\nWhen passion turns toxic Being passionate about your work is one of New Relic’s core values. In this case, however, we may have experienced too much of a good thing: our code reviews soon became collision points, and we increasingly turned to passive-aggressive communications to settle our differences.\nIn the example on the left, the reviewer left the PR in an in-between state. They didn’t explicitly reject it, but they didn’t approve it either. In the example on the right, the reviewer made a highly subjective request, and the author just made the change, but from their tone you can kind of guess that they didn’t appreciate the feedback.\nAs a result, the NRDB team’s developers grew increasingly frustrated, team trust eroded, and several members (myself included) contemplated switching to other teams. We were in trouble.\nRefining our process—and saving the team We decided as a team to take a step back; we resolved to figure out what was going on, why it was happening, and what we could do to fix it. Since most of our frustration was tied to our code reviews, we started by asking a simple question: how could we give one another more effective and constructive feedback?\nWe answered the question by developing four basic guidelines for code reviews. We think you’ll find them useful, too, but before we spell them out, we want to share the full story behind what happened to divide our team and what was really as stake for us.\nA flawed approach to the code review process Many of our challenges were related to the differences between objective and subjective feedback in our code reviews. Being able to differentiate clearly between these two types of feedback can be critical to the success of a code review, and to the effectiveness of a development team. In too many cases, we weren’t handling subjective feedback in a constructive manner—in fact, just the opposite was true.\nWe probably aren’t the only ones who struggle with this issue. Many developers are trained from the start to downplay differences between the two types of feedback. In fact, students in academic software engineering programs rarely learn how to give or receive critical feedback of any sort.\nWhen I went to school, this certainly was the case. The computer science curriculum focused on algorithm analysis, data modeling, and problem solving. Our instructors treated code review as a functional quality-assurance task; they rarely presented it as a creative process. Code review feedback tended to be straightforward: The code either worked, or it didn’t. Because of this kind of training—or rather, lack of training— many software engineers still treat all aspects of code reviews as completely objective activities.\nIt’s useful to contrast this approach with the one employed in an academic creative writing program. There, instructors conduct workshops that include training on how to give critical feedback. Creative writing instructors understand that giving and receiving critical feedback is an essential part of the creative process. They also understand, however, that critical feedback can be harmful and create resentment unless it is handled properly. The goal is to provide feedback in a positive and constructive way that helps to hone a writer’s ideas, enhance their creativity, and leave both parties enriched by the process.\nThe struggle over subjectivity Many facets of a code review, however, are not straightforward. In particular, there are issues that demand subjective assessments for which there are no “correct” answers. This is where the rigid emphasis on code review as a totally objective activity, and the failure to consider the creative nature of software development, can become a problem.\nMany elements of a modern code review process are now fully automated. Editors and IDEs will find syntax errors, evaluate Boolean logic, and warn about infinite loops. As a result, the bugs that survive are much harder to find, especially when you’re at the end of the process and are just looking at a code snippet with limited context.\nEditors and IDEs, however, can’t detect—or prevent developers from focusing on—subjective issues such as confusing method names, questionable style preferences, and bad variable formatting. And when we dislike and disagree with what we find in such cases, we often forget that these \u0026ldquo;flaws\u0026rdquo; are subjective matters of opinion—not objective matters of fact.\nThis approach also makes it easy to forget that a debate over subjective issues during a code review can get emotional and heated very quickly.\nSome teams try to regulate this problem out of existence by creating style guides that make objective rules out of subjective preferences. This approach rarely succeeds: software development is full of subjective choices, and there is no way to cover every subjective choice that developers may face in the course of project.\nWhen a team lacks a clear communication channel for subjective feedback, the problem gets even worse. Reviewers may mix their subjective and objective comments without acknowledging the differences; here too, the process can end in resentment, frustration, and a breakdown in team communication.\nOur four guidelines for code reviews This brings us back to the guidelines we developed to govern the subjective elements of the NRDB team’s code review process.\nFirst, as a preliminary to our four guidelines, we agreed to define who is ultimately responsible for the correct execution of any code changes. This was important to us because in a subjective debate, the opinions of the person who has the ultimate responsibility—in other words, verifying code execution— should carry the most weight. As a result, we decided that \u0026ldquo;The author of the code change is responsible for the correct execution of the change.\u0026rdquo;\nThis may seem obvious, but not all teams work that way. Some teams, for example, treat the review process as a QA process where the reviewer is ultimately responsible for verifying correct execution.\nWe found that subjective comments were most often presented as objective feedback at the pull request stage of the process. As a result, this is where we focused our code review guidelines.\nIn creating these rules, we laid a foundation for team members to clearly identify what a code reviewer should look for, and how to give both subjective and objective feedback. Here are the guidelines:\n  The reviewer should identify errors that will cause an issue in production. It’s a code review, after all, so the reviewer should identify missing semicolons, unending loops, or missing error handling. Reviewers aren’t responsible for finding all such errors (that’s still the responsibility of the author), but they should be on the lookout for obvious issues that will break the system if they’re are deployed into production. Such issues are a valid reason to block the pull request.\n  The reviewer should verify that the stated goal of the code change aligns with the changes being made. If the author submits a pull request that says they’re making changes to the networking code of a service, reviewers should expect that all of the changes are in and around the service’s networking code. This seems obvious, but it’s no secret that developers have a tendency to try to pack in multiple changes in such cases. This isn’t even necessarily a wrong practice, as long as the changes are mostly co-located. When you align a code change to its stated goal, however, you make it easier to determine if the pull request potentially submits any new bugs. Here, too, we agreed that failing to align the code change with its stated goal would justify blocking the pull request.\n  The reviewer should verify that any changes align with the team’s coding standards. I’ll cover this more in a bit, but as an example, if the team has decided that all variables must use camel case, and the reviewer finds a variable that does not use camel case, they should block the pull request.\n  The reviewer should look for anything they personally disagree with. This guideline addresses any comment which the first three rules do not cover. We want reviewers to give feedback, even if it’s not covered by the first three rules. We didn’t want our guidelines to suppress feedback, which is essential for how we learn from one another. Because these comments are clearly subjective, however, we agreed that they do not justify blocking the pull request.\n  To remove all confusion, we ask that reviewers specifically call out their comments as either blocking or non-blocking; and to add those comments as tags in their reviews. For example:\nObjective comments\n \u0026ldquo;Blocking: You are missing a semicolon.\u0026rdquo; \u0026ldquo;Blocking: This loop never ends.\u0026rdquo; \u0026ldquo;Blocking: You are missing some error handling here\u0026rdquo;  Subjective comments\n \u0026ldquo;Non-blocking: Your method name is not clear enough.\u0026rdquo; \u0026ldquo;Non-blocking: You should put the open curly brace on the line above.\u0026rdquo; \u0026ldquo;Non-blocking: You should use camel case for your variable here and not snake case.\u0026rdquo;  Working within our code review guidelines As we adopted these guidelines, the team had the most difficulty with the fourth one. Adopting this meant we had to accept two conditions:\n  The code our team produced did not need to be uniform. This meant overcoming a trend in our industry that says you should strive to remove all fingerprints from your code that identifies who wrote what part. We found the ROI on following this trend was pretty low, and trying to do so just led us back into the same subjective debate: If a developer writes code in a manner slightly different than their peer would, does that mean the code is incorrect? Clearly, we decided, that wasn’t the objective case.\n  If a reviewer adds non-blocking feedback, the author should take the time to consider it. Early on, some team members were concerned that authors would simply ignore all non-blocking comments, as their code was no longer blocked by subjective feedback. Our solution, then, was to reiterate that \u0026ldquo;we trust our teammates.\u0026rdquo; If, as reviewers, we took the time to enter a comment, we trusted that the author would take the time to read and consider it.\n  These both were contentious points, and the team spent a long time debating them. But ultimately, we found that the only way to work through these issues successfully is to live with the guidelines and give them a chance.\nSponsoring a coding standard So, what are a reviewer’s options if they see something which they passionately feel shouldn’t be in the code, especially if their concern isn’t an \u0026ldquo;objective\u0026rdquo; rule violation they can block on? For such concerns, we agreed that a reviewer could choose to sponsor an addition to the team’s coding standards.\nEvery two weeks, we hold a retrospective meeting where team members are welcome to suggest changes or additions to our coding standards. There are two restrictions to this activity:\n  We cannot describe coding standards in subjective language. For example, a sponsor can’t say, \u0026ldquo;variables must not be ambiguous,\u0026rdquo; as ambiguity is subjective. But, the sponsor could add a standard that states, \u0026ldquo;variables must use Hungarian notation,\u0026rdquo; as this is objective and easily enforceable.\n  If you sponsor a coding standard, you must support it. The sponsor must provide documentation and training as needed. If there was a plugin or other tool the team needs to installed, the sponsor is responsible for supporting it. This restriction ensures the sponsor is passionate about anything they want to add to the team’s coding standards.\n  Finding respect and compromise in code reviews After agreeing to these guidelines, we cleared all our existing coding standards and started over. For the first few weeks it was hard to break old habits, and we had to remind several team members to add the blocking and non-blocking tags during their pull request reviews. But once we got rolling with the new guidelines, we saw a number of successes.\nFirst, by forcing reviewers to clearly identify those comments that were subjective, we noticed a change in how reviewers phrased their comments.Reviewers can no longer demand changes that meet their preferences; instead, they must request changes politely, and explain why they’re requesting the change. When we provide more explanation and context in this manner we create an environment that makes it easier for teammates to learn from one another. Plus, asking for changes, rather than demanding them, shows respect and acknowledges that the code’s author has valid feelings about their work, as well.\nWe also noticed that when a reviewer did write a non-blocking comment asking for a change, the author typically made the requested change or came up with a compromise—even though the author had the option of ignoring the comment. This demonstrates why asking for changes, rather than demanding them, builds stronger teams: the author feels less resentful, and the reviewer feels that the author genuinely appreciated their feedback.\nWe’ve identified a few other terrific benefits from this process. By limiting the scope of what qualifies as a blocking comment, for example, we reduced the time it took us to approve and merge changes, which resulted in greater overall project velocity. We have also reduced the time required to onboard new new team members and to get them up to speed with our code review process.\nWe have also updated our training materials to reflect our new code review process: We distribute one page that documents our guidelines, and another page that documents our coding standards. New team members now know exactly what they should be looking for and how best to communicate their suggestions.\nWe also expected the number of coding standards to increase greatly as reviewers sponsored new standards for items they could no longer block on. At the beginning, we did adopt several new coding standards, but after an initial burst, the number of new agreements fell off significantly. We concluded that since reviewers felt that authors were taking into consideration their subjective feedback, they did not feel as motivated to \u0026ldquo;convert\u0026rdquo; them to objective constraints based on their point of view.\nThese guidelines aid in team autonomy The most important thing about these guidelines is that they support team autonomy; in no way do these guidelines dictate which coding standards teams should adopt. Teams are free to choose their own style guides, and they decide how strict they want to to be. These guidelines simply explain how to define coding standards and how reviewers should look for and give feedback.\nWe have come to appreciate the role that a strong and effective feedback process can have on building team morale, increasing team trust and communication, and improving development velocity. We implemented guidelines to strengthen the feedback process and to address issues that put the process at risk—and so far, I think we’re getting exactly what we hoped to get from these improvements.\n","date":1539043200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1539043200,"objectID":"5261e3eded1eedf0533e0a4867fc20f2","permalink":"/post/code-reviews/","publishdate":"2018-10-09T00:00:00Z","relpermalink":"/post/code-reviews/","section":"post","summary":"The following is a blog post that was written from a speech I gave about how to set the ground rules for code reviews.\n Following New Relic’s Project Upscale—an innovative reorganization intended to make our development teams more autonomous—the engineering organization formed several new teams, one of which was the New Relic Database (NRDB) team. As the name implies, the NRDB team is responsible for the development of our events database, which powers the New Relic Insights tool as well as several other products.","tags":null,"title":"Creating Simple and Effective Guidelines for Code Reviews","type":"post"},{"authors":["Joshua Gerth"],"categories":["Software Development","Java"],"content":"Java's dependency management suffers from the dreaded diamond dependency issue. And while this issue is not unique to Java, it is, perhaps, more acute due to the precompiled nature of Java's Jar files.\nA Quick Refresher If you are unfamiliar with this issue, here is a quick refresher:\nSuppose there exists a library which contains a useful method that takes a string as its parameter:\nclass Common { void helpful(String a) { ... } }  This library is published to an artifactory as\n com.hrakaroo : common : 1.0  Now, suppose there exists two other libraries which both use this helpful method\nclass Dog { void method1() { Common c = new Common(); c.helpful(\u0026quot;dog\u0026quot;); } }  and\nclass Cat { void method2() { Common c = new Common(); c.helpful(\u0026quot;cat\u0026quot;); } }  Each of these are also published to artifactory as:\n com.hrakaroo : dog : 1.0 com.hrakaroo : cat : 1.0  And each of these have a transitive dependency on Common. Okay, now you decide to build your service which uses Dog and Cat so your dependency tree looks like\n com.hrakaroo : dog : 1.0 com.hrakaroo : common : 1.0 com.hrakaroo : cat : 1.0 com.hrakaroo : common : 1.0  All is good. But now the folks who created Common come out with a new version which changes the signature of helpful and adds a boolean flag. So the new version looks like\nclass Common { void helpful(String a, boolean flag) { ... } }  And knowing they are going to break some things publish this under a new version in artifactory\n com.hrakaroo : common : 2.0  The folks who made the Cat library realize this new flag will fix a bug they have had so they update to it as\nclass Cat { void method2() { Common c = new Common(); c.helpful(\u0026quot;cat\u0026quot;, true); } }  And publish it under\n com.hrakaroo : cat : 2.0  But the Dog library makers don't need the new functionality so they don't bother to update.\nAnd finally, you decide to update your service to use the newest version of Cat which has the bug fix you need. This changes your dependency tree to:\n com.hrakaroo : dog : 1.0 com.hrakaroo : common : 1.0 com.hrakaroo : cat : 2.0 com.hrakaroo : common : 2.0  In Java 8 you can not bring in the same dependency more than once with different versions. There are two common ways to deal with this, and they are both wrong.\nFirst, you can not do anything. (This is probably the most popular solution.) In this situation gradle will pick one (usually the latest version) and use that as its version. In this case it will select com.hrakaroo : common : 2.0 which means that when your service calls Dog.method1 it will give you a runtime exception as the JVM will be unable to find the definition for helpful(String).\nOr, if you are using gradle, you can use it's force tag and force the version down to com.hrakaroo : common : 2.0 which means that when your service calls Cat.method2 it will give you a runtime exception as the JVM will be unable to find the definition for helpful(String, boolean)\nThe only \u0026ldquo;correct\u0026rdquo; solution here is to use gradle's failOnVersionConfict() which will fail to compile your project unless both your dog and cat dependencies use the same version. This means you will be forced to fix the issue before your project can compile, but this may not be practical as a large project has lots of moving parts and compatible versions may not be available. Additionally, failOnVersionConflict() doesn't understand semantic versioning so it will fail on PATCH level differences which often makes this a very painful and non-practical solution.\nMost people just choose to go with the plug-and-pray approach where they just hope they never call a code path which encounters a definition which doesn't exist.\nCutting the knot As the two easy solutions are wrong and the one correct solution is impratical, the only real answer here is to avoid the problem altogether. When building a library, limit your dependencies.\nBuilding a service requires a different approach from building a shared library. From the technologies you use to the way you version and test it are substantially different. Services are often just thin wiring together of different frameworks and libraries while libraries are more single tasked. And yet, they too often I don't see people appreciate this difference. Instead they hack together libraries like they do services.\nStick to vanilla Java I really like the Kotlin language, but I don't think it has a place (yet) in shared libraries. Part of what makes Kotlin fun are all of the extension and infix libraries which are all packaged in the kotlin stdlib dependency. Any time you have more than two kotlin library dependencies you are just about assured to have a version conflict on the kotlin stdlib. Libraries should be written in Java to remove as many dependencies as possible.\nAvoid huge common or utility libraries Apache's commons-lang3 is a fantastic library, but too often I've seen brought in so that the developer can use the StringUtils.join() method. Not only is this method trivial to write, but with Java 8 this can be done directly off the stream using .collect(Collectors.joining(...)).\nThe same can be said for Google's Guava library, which is an enormous library that often makes non-compatible changes. In one library I reviewed the author had brought in a dependency on Guava so that they could use the Preconditions checks. While I think this type of defensive programming is good, the precondition checks can easily be re-created in your own library.\nCopy and attribute Providing the license allows it, it is also okay to simply copy sections of your dependent library directly into your own shared library and remove the dependency. Be sure to attribute where you got it from, but otherwise copying small to medium sized dependencies is okay.\nRelocate and attribute Finally, if all of the above are failing for you and, again if the licensing allows it, you can use a tool like shadow/shade to relocate a dependent library directly into you own library. These tools can will rebuild your resulting jar so that your dependencies are no longer transitive and all references to their old location have been changed to somewhere in your package. So, for example, you could relocate com.apache.commons to com.hrakaroo.apache.commons.\nThis will increase your jar size so it should really be used as the last resort, but it will guarantee that no one can later change the depenency version to something which is incompatable.\nWhatever your approach, you should take the time when creating a shared library to minimize it's transitive dependencies as much as possible. By doing so you will help minimize the risk to developers which use your library of creating their own diamon dependency nightmare.\n","date":1527811200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1527811200,"objectID":"a0e358f5affd08037816053c726d50d9","permalink":"/post/sane-java-dependency-management/","publishdate":"2018-06-01T00:00:00Z","relpermalink":"/post/sane-java-dependency-management/","section":"post","summary":"An approach to Java's dependency management problem","tags":null,"title":"Trying to solve Java's Gordian Knot","type":"post"},{"authors":["Joshua Gerth"],"categories":["Toastmasters"],"content":"The following is the speech I wrote for the Humorous Speaking Contest for Toastmasters. I placed first for the Division award but had to back out of competing at the Area level due to a travel conflict.\nThis speech is intended to be performed so it is not a formal writing.\n My wife, who usually took our 10 year old daughter to her dance recitals, had been asked to speak at a conference that coincided with a recital, so I was tasked with taking our daughter instead. While this might stress out some fathers, it so happened that I was an experience dancer dad. My work schedule was very flexible so I had become primarily responsible for taking our daughter to her dance classes. I had spent hours at the dance studio and I’d seen it all. From temper tantrums, to crying and yelling and throwing things… and that was just the moms. I wasn’t worried in the least.\nMy first task was to take her to get her makeup for the recital. \u0026ldquo;Black eyeliner, red lipstick.\u0026rdquo; That seemed straightforward, but when we got to the makeup counter we found out there isn't just one black eyeliner. There’s regular black, black out, onyx black, darkest black, ferocious black and blackest black, just to name a few. I must not be the most color aware person as all the different shades of black looked pretty similar to me. There were also water proof versions of everything which I ruled out instantly as we were certainly not going swimming. So we eventually narrowed it down to darkest black and blackest black, which seems like an absurd differentiation. I don’t know how you get to darkest without also being the blackest but far be it from me to question a multi-billion dollar industry. After much back and forth we finally settled on blackest black as we figured that way no one could complain it wasn’t black enough. The lipstick was a bit easier as the instructions had included a specific shade number.\nHowever, it wasn’t until the day of the recital that I realized neither my daughter nor I had ever actually applied either eyeliner or lipstick. These days you could probably find an instruction video on-line, but this was pre-YouTube days. We decided to tackle the eyeliner first. For those that don't know, an eyeliner pencil is essentially a sharpened stick which you need to get really close to the eye. The entire concept seems barbaric and on my first attempt I couldn’t bring myself to actually get right up next to her eye. This left her with a ring around her eye. Knowing this wasn’t quite correct I tried to fix it by coloring from the edge of the ring closer in towards her eye. Although in theory this worked, the end result was far more goth than I had intended.\nThe lipstick proved to be almost as challenging as the eyeliner, although less dangerous. To me, lipstick seems like a sticky crayon and your lips have a natural line on them that separates them from the rest of your face, so I figured if I just colored in between the lines I would be good to go. What I didn’t account for was that there is no natural stopping point inside your mouth and I spent a good while in front of the mirror making various lip poses trying to get a sense of how far in I should color.\n\u0026ldquo;Dad!\u0026rdquo;\nNone of this was sitting well with my daughter who was becoming more and more panicked with each facial gesture. After deciding on a general plan I proceeded to put on the lipstick much like you would color in a coloring book, with rapid back-and-forth type motion. Again, although in theory this worked it left her with a very thick layer of lipstick on her lips.\nStill, with the makeup done we rushed off to the dance recital. I got her checked in and took my seat in the audience.\nThe recital started normally but it didn’t take long before the hot overhead lights, heavy costumes and general physical activity started to take their toll. Like most of the dancers, my daughter started to sweat … heavily. This is apparently what waterproof eyeliner is for. Without it the sweat mixed with the thick ring I had applied and proceeded to run down her cheeks, giving her an Alice Cooper look. Meanwhile, the lipstick I had applied in her mouth had been rubbing against her teeth turning them a frightening shade of red and causing her smile to take on a menacing grimace. This added new meaning to the dance as it appeared my daughter was melting into a nightmarish black swan, threatening to eat the other dancers.\nStuck in the audience I could only watch with mounting horror as the thick layer of lipstick started to work itself outside her lips and smear around her face. My first thought was \u0026ldquo;my wife is going to kill me.\u0026rdquo;\nThankfully some of the other moms took pity on her and tried to clean her up between routines. When my wife returned and saw the recital photos she decided that she would never miss another dance recital again. My daughter recovered but has learned that dad is not who you go to for makeup advice. Still, whenever my kids ask me if they should wear the blue outfit or the black one, I like to respond with \u0026ldquo;now is that the darkest black one or the blackest black one?\u0026rdquo;\nThank you.\n","date":1506816000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1506816000,"objectID":"67fabd34e881ed36b32cff0c521f45f5","permalink":"/post/the-dance-recital/","publishdate":"2017-10-01T00:00:00Z","relpermalink":"/post/the-dance-recital/","section":"post","summary":"Award winning speech for the Toastmasters Humorous Speaking Contest","tags":null,"title":"The Dance Recital","type":"post"},{"authors":["Joshua Gerth"],"categories":["Development Process","Teams"],"content":"In the traditional standup format everyone stands in a circle and each person, in order, gives an update. The updates follow the Agile format:\n What they did yesterday What their plans are for today Are there any blockers  I have a number of problems with this format.\nContext Switching People don’t usually stand in any particular order so the updates from person to person often jump between the project(s) the team is working on and hero tasks. Additionally, if we’ve sized our tasks correctly often what one person is working from day to day changes. This makes sense to the person giving the update, but for everyone else, trying to track actual progress becomes increasingly difficult.\nProject Status Related to context switching, it’s nearly impossible tell the overall project status from this type of update. Even if you could figure out how many tickets were closed, without looking at the kanban board it’s impossible to get even a sense of how far along the project is. Plus, this format does nothing to encourage people to actually update the kanban board, compounding the issue.\nPublic Speaking Public speaking does not come naturally to everyone, even when presenting just to the team. I’m much more relaxed with it now, but there was a time when this type of setting would cause me enough stress and I would ignore whatever was being said and just rehearse what I was going to say. Then, after I gave my update, I would spend rest of the standup obsessing over the things I had messed up or forgotten to say.\nCompetition for Busiest Without focus, the standup can become a passive competition for who is the busiest person.\n I've got a meeting with a customer today to talk over a feature they want added. Well I've got two meetings today to talk over features. I've pretty much got meetings all day long so I'm not likely going to get much else done.  It sounds silly, but it's something I've seen happen a lot at multiple companies, especially if people are feeling insecure (imposter syndrome). It can take the form of lamenting (but really bragging) about the number of meetings, or making the tasks you completed sound like herculean efforts. It's pointless and unhealthy for the team.\nForced Update Finally, it forces everyone to talk when they may not want to. There have been times in my career where my personal life has taken over and I’ve needed to take some time off. Be it medical or family related. At the update I don’t want to go into details about what I’m dealing with. In fact, I may be at work specifically to take a break from the other stresses going on. Perhaps I took off work yesterday and I may have to leave early today to take care of a personal issue, but now I'm in an unconformable position of either saying \u0026ldquo;I have no update\u0026rdquo; or, worse, explain that \u0026ldquo;I've got some things going on which I don't want to talk about.\u0026rdquo;\nAs an individual contributor I find this standup format stressful and as a project lead and manager I find it unhelpful. Instead I prefer using the standup time to walk the kanban board.\nWalking the board With a Jira you can use swim planes to split up your kanban board into project tasks and hero tasks. Then starting at the Done column, just go down each column and each owner gives an update for their task. In this format there is no initial awkward moment trying to figure out who should go first. The context switching is much less and the team can focus on what is being said instead of trying to memorize what they are going to say.\nSince Done is often an end state and you don't necessarily want to re-walk this entire list every time you can either cut a Jira release after each standup, or create a Closed column and use the standup as an opportunity to move tasks from Closed to Done.\nClosing comments One critique of this format is that it is possible for a team member not working on a task to feel left out. If they really are attending meetings all day there is a chance to they haven't picked up any tasks and therefore won't speak. So, at the end of the standup ask a quick question for any closing or final comments. This is the opportunity to team members to say \u0026ldquo;I need to leave early today,\u0026rdquo; but I would keep the focus on today and away from team members trying to justify their time from yesterday. If there really is a concern about yesterday that should be brought up directly in their 1:1 with their manager and not the team.\nAs a project lead and manager I find walking the board to be significantly more useful as I can tell exactly the progress of the project (as I’m looking at the tickets) and I can also be sure that Jira tickets for the project are up to date. As an individual contributor I don't feel like I have to prepare as much for this standup and I can just attend and focus on what everyone else is saying.\n","date":1499558400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1499558400,"objectID":"de7f74e948afa249aab52c76a0875be3","permalink":"/post/walking-the-board/","publishdate":"2017-07-09T00:00:00Z","relpermalink":"/post/walking-the-board/","section":"post","summary":"Running a productive focused standup","tags":null,"title":"Walking the board","type":"post"},{"authors":null,"categories":null,"content":"One Seat Open, an invitation system for limited seating events.\nHistory This project primarily came from a personal frustration in hosting my own game nights. Most invitation systems I researched were open ended (no wait list support) or were so chock full of ads that I could barely navigate them. At the same time I was also looking for a project with which to learn front end development as I have been mostly focused backed development. So this seemed like a perfect opportunity to build my own service.\nDevelopment After researching several frontend frameworks I eventually settled on Vue.js with the Vuetify plugin for several reasons. Vue.js was established enough to have good tutorials, training videos and a robust presence on Stack Overflow for questions. It also had an easy ramp up and it didn't originate from Facebook. (Petty, I know, but I have a personal distain of Facebook).\nStatus In November of 2019 I launched the site and moved hosting my game night to the system so I can start \u0026ldquo;eating my own dog food.\u0026rdquo; I still have several large features I want to add before I really start start trying to push it more globally.\nFor now I'm keeping it closed source, but free to use. If the service proves popular I will likely be forced to add either a for-pay section or ads to cover my hosting fees, but otherwise I have no immediate commercialization plans for the service.\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"a7deca733f1b099c5162b295dde0da1d","permalink":"/project/one-seat-open/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/one-seat-open/","section":"project","summary":"Invitation system for events with limited seating","tags":["Kotlin","Vuejs"],"title":"One Seat Open","type":"project"},{"authors":null,"categories":null,"content":"","date":1171065600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1171065600,"objectID":"6b6d705afcb01a42443d6c99626aade9","permalink":"/project/rebound/","publishdate":"2007-02-10T00:00:00Z","relpermalink":"/project/rebound/","section":"project","summary":"A reimplementation of the Diamonds game in C++/SDL","tags":["Cpp"],"title":"Rebound","type":"project"},{"authors":null,"categories":null,"content":"","date":1100995200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1100995200,"objectID":"fcc1d44d4717750fa7081ebd91949b9a","permalink":"/project/soda-water-ray-tracer/","publishdate":"2004-11-21T00:00:00Z","relpermalink":"/project/soda-water-ray-tracer/","section":"project","summary":"Ray Tracer written in C++ for graduate program","tags":["Cpp","RayTracer"],"title":"Soda Water Ray Tracer","type":"project"}]